{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ellylai/15-112-TP/blob/main/hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1JMXtrjJXpm"
      },
      "source": [
        "# 10-315 S25 HW1: Nearest Mean Classification and Neural Networks\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/nearest_mean_summary.png\" width=\"400\"/>\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/autoencoder_network_summary.png\" width=\"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6HA7ylxJXpp"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "## [Setup (cells to just run)](#setup)\n",
        "## [Q0: Autograder introduction](#q0)\n",
        "## [Q1: Nearest mean classification](#q1)\n",
        "## [Q2: Neural Networks](#q2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rh9Bzeh6JXpq"
      },
      "source": [
        "# Setup <a class=\"anchor\" name=\"setup\"></a>\n",
        "\n",
        "You'll need to run these cells, but you don't have to worry about their contents. You can look through them if you'd like of course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ju9ULJxJXpq"
      },
      "outputs": [],
      "source": [
        "# Install otter-grader if needed\n",
        "\n",
        "import importlib\n",
        "\n",
        "if importlib.util.find_spec(\"otter\") is None:\n",
        "    !pip install otter-grader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kla1Vf74JXpr"
      },
      "outputs": [],
      "source": [
        "# Copy additional files if needed\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.isdir(\"tests\") or not os.path.isdir(\"autoencoder\"):\n",
        "    !curl https://www.cs.cmu.edu/~10315/assignments/hw1_additional_files.zip --output hw1_additional_files.zip\n",
        "    !unzip hw1_additional_files.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVm2niNIJXps"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import otter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3j7WoezKJXps"
      },
      "outputs": [],
      "source": [
        "grader = otter.Notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_ix9hBVJXpt"
      },
      "source": [
        "## Functions to load data\n",
        "\n",
        "You'll need to run these cells, but you don't have to worry about their contents. You can look through them if you'd like of course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLP1nkMpJXpt"
      },
      "outputs": [],
      "source": [
        "def load_dataset(filename, num_train):\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    # Pull label names out of label column header\n",
        "    # Assuming the format is \"Label (label1,label2,label3)\"\n",
        "    label_header = df.columns[0]\n",
        "#     label_names_string = re.split(r'\\(|\\)', label_header)[1]\n",
        "#     label_names = label_names_string.split(',')\n",
        "    if '(' in label_header:\n",
        "        label_names_string = re.split(r'\\(|\\)', label_header)[1]\n",
        "        label_names = label_names_string.split(',')\n",
        "    else:\n",
        "        label_names = [label_header]\n",
        "\n",
        "    feature_names = list(df.columns[1:])\n",
        "\n",
        "    y_train = df.values[:num_train, 0]\n",
        "    y_test = df.values[num_train:, 0]\n",
        "\n",
        "    x_train = df.values[:num_train, 1:]\n",
        "    x_test = df.values[num_train:, 1:]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test, label_names, feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9pErI85JXpt"
      },
      "outputs": [],
      "source": [
        "def load_animals_dataset():\n",
        "    num_train = 60\n",
        "    return load_dataset('http://www.cs.cmu.edu/~10315/data/animals1.csv', num_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnGSuS16JXpu"
      },
      "outputs": [],
      "source": [
        "def load_iris_dataset():\n",
        "    num_train = 120\n",
        "    return load_dataset('http://www.cs.cmu.edu/~10315/data/iris.csv', num_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOUZwyBbJXpu"
      },
      "outputs": [],
      "source": [
        "def load_iris_dataset_two_features():\n",
        "    x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset()\n",
        "    # Grab only the first two columns\n",
        "    x_train = x_train[:, :2]\n",
        "    x_test = x_test[:, :2]\n",
        "    return x_train, y_train, x_test, y_test, label_names, feature_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv4xCWsSJXpu"
      },
      "outputs": [],
      "source": [
        "# Including a \"cache\" trick to avoid re-reading this 70,000 image dataset every time we want to use it\n",
        "cached_digit_dataset = None\n",
        "\n",
        "def load_digit_dataset():\n",
        "    global cached_digit_dataset\n",
        "\n",
        "    # Check to see if we have already loaded this before\n",
        "    if cached_digit_dataset is not None:\n",
        "        return cached_digit_dataset\n",
        "\n",
        "#     num_train = 60000\n",
        "#     cached_digit_dataset = load_dataset('http://www.cs.cmu.edu/~10315/data/mnist.csv', num_train)\n",
        "    num_train = 900\n",
        "    cached_digit_dataset = load_dataset('http://www.cs.cmu.edu/~10315/data/mnist_1000.csv', num_train)\n",
        "\n",
        "    return cached_digit_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E-JPCR2JXpu"
      },
      "outputs": [],
      "source": [
        "# Source:\n",
        "#     https://archive-beta.ics.uci.edu/ml/datasets/metro+interstate+traffic+volume\n",
        "#     Hogue, John. (2019). Metro Interstate Traffic Volume. UCI Machine Learning Repository.\n",
        "def load_traffic_dataset():\n",
        "    num_train = 300\n",
        "    return load_dataset('http://www.cs.cmu.edu/~10315/data/Metro_Interstate_Traffic_Volume_weekday_hour_small.csv', num_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92k8J7hfJXpv"
      },
      "source": [
        "## Functions to plot data and display images\n",
        "\n",
        "You'll need to run these cells, but you don't have to worry about their contents. You can look through them if you'd like of course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LT2sBwoJXpv"
      },
      "outputs": [],
      "source": [
        "# Bump up the default font size for matplotlib\n",
        "plt.rcParams.update({'font.size': 8})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amqFIYpHJXpv"
      },
      "outputs": [],
      "source": [
        "def plot_points(x_data, feature_names=None):\n",
        "    label_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\"]\n",
        "    color = label_colors[0]\n",
        "\n",
        "    if feature_names is None:\n",
        "        feature_names = ['Feature 1', 'Feature 2']\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plt.plot(x_data[:, 0], x_data[:, 1], 'o', markersize=6,\n",
        "             markerfacecolor=\"None\", markeredgecolor=color)\n",
        "\n",
        "    plt.xlabel(feature_names[0])\n",
        "    plt.ylabel(feature_names[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJMpAb3gJXpv"
      },
      "outputs": [],
      "source": [
        "def plot_labeled_points(x_data, y_data, label_names, feature_names=None):\n",
        "    label_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\"]\n",
        "\n",
        "    if feature_names is None:\n",
        "        feature_names = ['Feature 1', 'Feature 2']\n",
        "\n",
        "    num_labels = len(label_names)\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    for label in range(num_labels):\n",
        "        # Numpy trick to get just the rows of x_data corresponding to rows of\n",
        "        # y_data that equal the current label.\n",
        "        # This will still have the same number of columns as x_data but only\n",
        "        # a subset of the rows.\n",
        "        x_data_subset = x_data[y_data == label]\n",
        "\n",
        "        plt.plot(x_data_subset[:, 0], x_data_subset[:, 1], 'o', markersize=6,\n",
        "                 markerfacecolor=\"None\", markeredgecolor=label_colors[label], label=label_names[label])\n",
        "\n",
        "    plt.legend()\n",
        "    plt.xlabel(feature_names[0])\n",
        "    plt.ylabel(feature_names[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0t_wwhPJXpv"
      },
      "outputs": [],
      "source": [
        "def plot_mean_points(means, label_names=None, feature_names=None):\n",
        "    label_colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\", \"tab:purple\", \"tab:brown\", \"tab:pink\", \"tab:gray\", \"tab:olive\", \"tab:cyan\"]\n",
        "\n",
        "    if feature_names is None:\n",
        "        feature_names = ['Feature 1', 'Feature 2']\n",
        "\n",
        "    if label_names is None:\n",
        "        num_labels = 1\n",
        "    else:\n",
        "        num_labels = len(label_names)\n",
        "\n",
        "    for label in range(num_labels):\n",
        "        if label_names is None:\n",
        "            label_name = \"\"\n",
        "        else:\n",
        "            label_name = f'Mean {label_names[label]}'\n",
        "        plt.plot(means[label][0], means[label][1], 's', markersize=6,\n",
        "                 color=label_colors[label], label=label_name)\n",
        "\n",
        "    if label_names is not None:\n",
        "        plt.legend()\n",
        "    plt.xlabel(feature_names[0])\n",
        "    plt.ylabel(feature_names[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxUcmjCDJXpw"
      },
      "outputs": [],
      "source": [
        "def plot_regression_points(x_data, y_data, x_label=\"Input\", y_label=\"Output\", fig=None, color=\"tab:blue\", fill=False, label=None):\n",
        "#     if fig is None:\n",
        "#         fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "    if fill:\n",
        "        fill_color = color\n",
        "    else:\n",
        "        fill_color = \"None\"\n",
        "\n",
        "    plt.plot(x_data, y_data, 'o', markersize=5,\n",
        "             markerfacecolor=fill_color, markeredgecolor=color, label=label)\n",
        "\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOmDaAqHJXpw"
      },
      "outputs": [],
      "source": [
        "def plot_line(x_data, y_data, x_label=None, y_label=None, fig=None, color=\"tab:green\", label=None):\n",
        "#     if fig is None:\n",
        "#         fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "    plt.plot(x_data, y_data, '-', linewidth=2, color=color, label=label)\n",
        "\n",
        "    if x_label is not None:\n",
        "        plt.xlabel(x_label)\n",
        "    if y_label is not None:\n",
        "        plt.ylabel(y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjFhQEZKJXpw"
      },
      "outputs": [],
      "source": [
        "def plot_network_prediction(x_train, y_train, x_new,\n",
        "                            network, w11, b1, w21, b2, w31, w32, b3,\n",
        "                            x_label=\"Hour of day\", y_label=\"Traffic volume\",\n",
        "                            x_min=0, x_max=24):\n",
        "    fig = plt.figure(figsize=(5,4))\n",
        "\n",
        "    if x_train is not None and y_train is not None:\n",
        "        plot_regression_points(x_train, y_train, x_label=x_label, y_label=y_label, label=\"Training data\")\n",
        "\n",
        "    x_grid = np.linspace(x_min, x_max, 100)\n",
        "    y_grid = np.zeros(len(x_grid))\n",
        "    for i in range(len(x_grid)):\n",
        "        y_grid[i] = network(x_grid[i], w11, b1, w21, b2, w31, w32, b3)\n",
        "\n",
        "    plot_line(x_grid, y_grid, color=\"tab:green\", label=\"Prediction\", x_label=x_label, y_label=y_label)\n",
        "\n",
        "    if x_new is not None:\n",
        "        y_new = network(x_new, w11, b1, w21, b2, w31, w32, b3)\n",
        "        plt.plot(x_new, y_new, 'o', color=\"tab:purple\", markersize=8, label=f'Prediction x={x_new}')\n",
        "\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFtfEOWlJXpw"
      },
      "outputs": [],
      "source": [
        "def show_digit(x, y_meas=None, y_pred=None):\n",
        "    plt.figure(figsize=(1,1))\n",
        "    plt.imshow(x.reshape((28,28)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    if y_meas is not None:\n",
        "        title = f'Label: {y_meas}'\n",
        "\n",
        "        if y_pred is not None:\n",
        "            title += f' Predicted: {y_pred}'\n",
        "\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ulaehfc0JXpw"
      },
      "source": [
        "# Question 0: Autograder introduction <a class=\"anchor\" name=\"q0\"></a>\n",
        "\n",
        "Just a quick question so you can see the pattern to:\n",
        "- Implement a function for a given question\n",
        "- Run cells to test your code on your own\n",
        "- Run `grader.check` to execute local tests for a question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2PK8SnZCJXpw"
      },
      "source": [
        "Here is a simple function for you to implement. Fill this out to implement $x^2$.\n",
        "\n",
        "*Note*: Don't forget to `return` the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtXdEIojJXpx",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def square(x):\n",
        "    \"\"\" Compute the square of input value x\n",
        "\n",
        "        Input:\n",
        "        x: numerical value\n",
        "\n",
        "        Returns: x squared as a numerical value\n",
        "    \"\"\"\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6d0tY7vbJXpx"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local test.\n",
        "\n",
        "Are the output values what you expect them to be?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "23y9uXy2JXpx"
      },
      "outputs": [],
      "source": [
        "x = 2\n",
        "square(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HEiohMzaJXpx"
      },
      "outputs": [],
      "source": [
        "x = -1\n",
        "square(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "o-c-Ap1KJXpx"
      },
      "outputs": [],
      "source": [
        "z = 3\n",
        "square(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d1ClA7KLJXpx"
      },
      "outputs": [],
      "source": [
        "a = -3\n",
        "square(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7MitODSzJXpx"
      },
      "source": [
        "Feel free to add as many more test/debug cells as you want! You can add new cells anywhere you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "YJsVKoydJXpx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bhEgvlgjJXpy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Ne1YpuiMJXpy"
      },
      "source": [
        "Once you finish testing and debugging with your cells above, you can run the local autograder test by running `grader.check(<test_name_string>)`. These will run the same \"public\" tests that you will see later when you submit your notebook to Gradescope."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Shd4FHJkJXpy"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fp-XSB7JXpy"
      },
      "source": [
        "### Submit your code to Gradescope early and often\n",
        "\n",
        "There is no limit on the number of submissions to Gradescope, so as you complete parts of the assignment it is a really good idea to save your notebook and upload it to Gradescope.\n",
        "\n",
        "Not all of the tests are included in the local autograder. Some of the tests are \"hidden\" and only run in the server autograder on Gradescope.\n",
        "\n",
        "Before continuing with the rest of the assignment, go ahead and save your notebook (or click File->Download->Download .ipynb) and then upload your hw1.ipynb file to Gradescope under assignment HW1 (programming)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-gzI3IxTJXpy"
      },
      "source": [
        "# Question 1: Nearest Mean Classification <a class=\"anchor\" name=\"q1\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "aizZs3deJXpy"
      },
      "source": [
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/nearest_mean_summary.png\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "KVhY-zPkJXp3"
      },
      "source": [
        "## Q1: Table of Contents\n",
        "\n",
        "* [Q1a: Computing the mean](#q1a)\n",
        "* [Q1b: Compute the mean for each label](#q1b)\n",
        "* [Q1c: Nearest mean classification](#q1c)\n",
        "* [Q1d: Classification performance measure](#q1d)\n",
        "* [Q1e: Putting it all together](#q1e)\n",
        "* [Q1f: Exploring results](#q1f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EGOJ_q2aJXp4"
      },
      "source": [
        "## Q1 Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fZecZ-PWJXp4"
      },
      "source": [
        "In this question, we'll implement a modification of the standard nearest neighbor algorithm.\n",
        "\n",
        "### Nearest Neighbor Classification\n",
        "\n",
        "Standard nearest neighbor classification:\n",
        "* Use all of our training data\n",
        "* When predicting a label for a new point, compute the distances from the new point to *all training points*\n",
        "* Return the label associated with the closest *training data point*\n",
        "\n",
        "<img src=\"http://www.cs.cmu.edu/~10315/figures/nearest_process.png\" width=\"850\"/>\n",
        "\n",
        "### Nearest Mean Classification\n",
        "\n",
        "We first compute the mean point for each label in our training data:\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/nearest_means.png\" width=\"400\"/>\n",
        "\n",
        "Nearest mean classification:\n",
        "* Use just the mean point for each label\n",
        "* When predicting a label for a new point, compute the distances from the new point to *each mean*\n",
        "* Return the label associated with the closest *mean* data point\n",
        "\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/nearest_mean_process.png\" width=\"850\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "M2az0G7wJXp4"
      },
      "source": [
        "## Q1a: Computing the mean <a class=\"anchor\" name=\"q1a\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "X9XaThheJXp4"
      },
      "source": [
        "Compute the mean of N M-dimensional data points. To accomplish this we just take the mean for each dimension independently. <span style=\"color:red\">Note:</span> You must use NumPy in this function; no loops allowed. Points will be taken off during manual grading (autograder would still give full points).\n",
        "\n",
        "In the example below, there are N=4 2-dimensional points. The mean of feature 1 across all four points is 3.5 and the mean of feature 2 across all four points is 2.0:\n",
        "\n",
        "$$\\text{mean}_1 = \\frac{1}{4}\\big(2.0 + 3.0 + 4.0 + 5.0\\big) = 3.5$$\n",
        "\n",
        "$$\\text{mean}_2 = \\frac{1}{4}\\big(3.0 + 3.0 + 1.0 + 1.0\\big) = 2.0$$\n",
        "\n",
        "Generically, for dataset $\\mathcal{D} = \\{\\mathbf{x}^{(i)}\\}_{i=1}^{N}$, where $\\mathbf{x}^{(i)} \\in \\mathbb{R}^M$  $\\forall i \\in \\{1, \\dots, N\\}$, the mean, $\\boldsymbol{\\mu} \\in \\mathbb{R}^M$ of the dataset $\\mathcal{D}$ is:\n",
        "\n",
        "$$\\boldsymbol{\\mu} = \\frac{1}{N}\\sum_{i=1}^N \\mathbf{x}^{(i)}$$\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/mean_example.png\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ljXrJqmJXp4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def compute_mean(x_data):\n",
        "    \"\"\" Compute the mean of datapoints stored as rows in x_data\n",
        "\n",
        "        Input:\n",
        "        x_data: Numpy array with shape (N, M) where the rows are filled with N M-dimensional data points\n",
        "\n",
        "        Returns: Numpy array with shape (M,) containing the mean of x_data\n",
        "    \"\"\"\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "D4RDtd8DJXp4"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local tests.\n",
        "\n",
        "Are the results what you expect them to be?\n",
        "\n",
        "Feel free to modify these or add more cells to help you test your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "nej566eoJXp5"
      },
      "outputs": [],
      "source": [
        "points = np.array([[5, 0.0],\n",
        "                   [3, 0.0],\n",
        "                   [2, 0.0],\n",
        "                   [4, 0.0]])\n",
        "mean = compute_mean(points)\n",
        "plot_points(points)\n",
        "plot_mean_points([mean])\n",
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Ak2--iZ9JXp5"
      },
      "outputs": [],
      "source": [
        "points = np.array([[5, 1],\n",
        "                   [3, 3],\n",
        "                   [2, 3],\n",
        "                   [4, 1]])\n",
        "mean = compute_mean(points)\n",
        "plot_points(points)\n",
        "plot_mean_points([mean])\n",
        "plt.ylim(-0.1, 4.1)\n",
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DXOoV5XIJXp5"
      },
      "outputs": [],
      "source": [
        "points = np.array([[5, -2.0],\n",
        "                   [3, -3.0],\n",
        "                   [2, -1.0],\n",
        "                   [4, -4.0]])\n",
        "mean = compute_mean(points)\n",
        "plot_points(points)\n",
        "plot_mean_points([mean])\n",
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Jy1eTwDIJXp5"
      },
      "outputs": [],
      "source": [
        "points = np.array([[2.8, 2.7],\n",
        "                   [3.6, 1.2],\n",
        "                   [4.0, 1.9],\n",
        "                   [3.7, 4.9],\n",
        "                   [3.1, 3.4],\n",
        "                   [3.0, 2.6],\n",
        "                   [3.0, 1.8],\n",
        "                   [3.4, 1.6],\n",
        "                   [3.3, 1.7],\n",
        "                   [3.3, 1.3]])\n",
        "\n",
        "mean = compute_mean(points)\n",
        "plot_points(points)\n",
        "plot_mean_points([mean])\n",
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zVvcfKOvJXp5"
      },
      "outputs": [],
      "source": [
        "# Load the iris dataset (with just two features)\n",
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset_two_features()\n",
        "\n",
        "mean = compute_mean(x_train)\n",
        "plot_points(x_train, feature_names=feature_names)\n",
        "plot_mean_points([mean], feature_names=feature_names)\n",
        "mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ImG9x6gMJXp6"
      },
      "source": [
        "### More than two features\n",
        "\n",
        "If you implemented `compute_mean` function above correctly, no changes needed!! Your code should work on these example cells also!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mPhjkUQjJXp6"
      },
      "outputs": [],
      "source": [
        "points = np.array([[5, 0.0, 0.0, 0.0],\n",
        "                   [3, 0.0, 0.0, 0.0],\n",
        "                   [2, 0.0, 0.0, 0.0],\n",
        "                   [4, 0.0, 0.0, 0.0]])\n",
        "mean = compute_mean(points)\n",
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7lbMCG8YJXp6"
      },
      "outputs": [],
      "source": [
        "points = np.array([[5,  0.0, 2.0, 100.0],\n",
        "                   [3, -1.0, 2.0, 101.0],\n",
        "                   [2,  0.0, 2.0, 102.0],\n",
        "                   [4, -1.0, 2.0, 103.0]])\n",
        "mean = compute_mean(points)\n",
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "l2rEo8yRJXp6"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset()\n",
        "print(x_train.shape)\n",
        "mean = compute_mean(x_train)\n",
        "mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AdmBsn_VJXp6"
      },
      "source": [
        "### Mean for images\n",
        "\n",
        "If you implemented `compute_mean` function above correctly, no changes needed!! Your code should work on these example cells also!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GU7Vs_m2JXp6"
      },
      "source": [
        "Load MNIST handwritten digit dataset and display the first four images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-ByHRSh3JXp7"
      },
      "outputs": [],
      "source": [
        "# This may take a minute or so\n",
        "\n",
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_digit_dataset()\n",
        "print('x_train.shape:', x_train.shape)\n",
        "print('y_train.shape:', y_train.shape)\n",
        "print('x_test.shape:', x_test.shape)\n",
        "print('y_test.shape:', y_test.shape)\n",
        "print('label_names:', label_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d5zmNX_BJXp7"
      },
      "outputs": [],
      "source": [
        "print(x_train[0].shape)\n",
        "print(x_train[0])\n",
        "show_digit(x_train[0], y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cslkYQiUJXp7"
      },
      "outputs": [],
      "source": [
        "show_digit(x_train[1], y_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "NCtja0CBJXp7"
      },
      "outputs": [],
      "source": [
        "show_digit(x_train[2], y_train[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZMGEP7XTJXp7"
      },
      "outputs": [],
      "source": [
        "show_digit(x_train[3], y_train[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7ZP14yXtJXp7"
      },
      "source": [
        "Average all of the zeros and then average all of the fours. Your `compute_mean` function should work on these example cells also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "V9Gwd8JBJXp8"
      },
      "outputs": [],
      "source": [
        "# Numpy trick to get just the rows of x_data corresponding to rows of\n",
        "# y_data that equal the current label.\n",
        "# This will still have the same number of columns as x_data but only\n",
        "# a subset of the rows.\n",
        "label = 0\n",
        "x_train_only_zeros = x_train[y_train == label]\n",
        "print('x_train_only_zeros.shape:', x_train_only_zeros.shape)\n",
        "\n",
        "mean = compute_mean(x_train_only_zeros)\n",
        "print('mean.shape:', mean.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ShyDSSEwJXp8"
      },
      "outputs": [],
      "source": [
        "show_digit(mean, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Y1BWvnjZJXp8"
      },
      "outputs": [],
      "source": [
        "# Numpy trick to get just the rows of x_data corresponding to rows of\n",
        "# y_data that equal the current label.\n",
        "# This will still have the same number of columns as x_data but only\n",
        "# a subset of the rows.\n",
        "label = 4\n",
        "x_train_only_fours = x_train[y_train == label]\n",
        "print('x_train_only_fours.shape:', x_train_only_fours.shape)\n",
        "\n",
        "mean = compute_mean(x_train_only_fours)\n",
        "print('mean.shape:', mean.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "znVMwhpYJXp8"
      },
      "outputs": [],
      "source": [
        "show_digit(mean, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_Yy8EfiqJXp8"
      },
      "source": [
        "For fun, we could average all of the zero and one digits :) Your `compute_mean` function should work on this example cell also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jqFaRuNuJXp8"
      },
      "outputs": [],
      "source": [
        "# Get all x data for labels <= 1\n",
        "x_train_zeros_ones = x_train[y_train <= 1]\n",
        "\n",
        "\n",
        "mean = compute_mean(x_train_zeros_ones)\n",
        "show_digit(mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HicWOo8xJXp9"
      },
      "source": [
        "### Run the local autograder tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "xzwaWEjKJXp9"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q1a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHtAiA4cJXp9"
      },
      "source": [
        "### Again, remember to keep submitting to Gradescope as you go.\n",
        "\n",
        "This will help you to make sure you are passing the hidden tests as well as the local tests. It also is a good reminder to save your work and make sure you officially collect points in Gradescope. You wouldn't want to finish all of your work and then realize at the last minute that there was something wrong with Q1 that caused problems for your whole assignment in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fQ26WaOdJXp9"
      },
      "source": [
        "## Q1b: Compute the mean for each label <a class=\"anchor\" name=\"q1b\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "OJMOVfYfJXp9"
      },
      "source": [
        "To build our model for nearest mean classification, we first need to compute the mean for each label.\n",
        "\n",
        "For each label:\n",
        "1. Collect all of the input points with that label\n",
        "2. Compute the mean for that subset of input points\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/nearest_means.png\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c4N4a_8tJXp9"
      },
      "source": [
        "<span style=\"color:red\">Note:</span> Looping over the number of labels is acceptable. Other than that, you must use NumPy in this function rather than loops. Points will be taken off during manual grading (autograder would still give full points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0YaLhrNJXp-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def compute_mean_for_each_label(x_data, y_data, num_labels):\n",
        "    \"\"\" For each label value from 0 to num_labels-1, compute the mean of datapoints in the rows of x_data\n",
        "        that have corresponding entries in y_data\n",
        "\n",
        "        Input:\n",
        "        x_data: Numpy array with shape (N, M) where the rows are filled with N M-dimensional data points\n",
        "        y_data: Numpy array with shape (N,). The label value for each of the N points in x_data\n",
        "\n",
        "        Returns: Return a list of length num_labels, where i-th entry in the list is a Numpy array with\n",
        "                 shape (M,) containing the mean of datapoints in x_data with label equal to i.\n",
        "    \"\"\"\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "tdo6f5GwJXp-"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local tests.\n",
        "\n",
        "Are the results what you expect them to be?\n",
        "\n",
        "Feel free to modify these or add more cells to help you test your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LYexauDWJXp-"
      },
      "outputs": [],
      "source": [
        "x_data = np.array([[8, 10],\n",
        "                   [4, 22],\n",
        "                   [6, 20],\n",
        "                   [9, 12]])\n",
        "y_data = np.array([1, 0, 0, 1])\n",
        "\n",
        "num_labels = 2\n",
        "label_names = ['A', 'B']\n",
        "\n",
        "means = compute_mean_for_each_label(x_data, y_data, num_labels)\n",
        "\n",
        "plot_labeled_points(x_data, y_data, label_names)\n",
        "plot_mean_points(means, label_names)\n",
        "means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "guu1CKkMJXp-"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_animals_dataset()\n",
        "\n",
        "num_labels = len(label_names)\n",
        "\n",
        "means = compute_mean_for_each_label(x_train, y_train, num_labels)\n",
        "\n",
        "plot_labeled_points(x_train, y_train, label_names)\n",
        "plot_mean_points(means, label_names)\n",
        "means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ARqD0ptHJXp-"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset_two_features()\n",
        "\n",
        "num_labels = len(label_names)\n",
        "\n",
        "means = compute_mean_for_each_label(x_train, y_train, num_labels)\n",
        "\n",
        "plot_labeled_points(x_train, y_train, label_names)\n",
        "plot_mean_points(means, label_names)\n",
        "means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "VnBbO4-iJXp_"
      },
      "outputs": [],
      "source": [
        "# Load iris dataset with all four features\n",
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset()\n",
        "\n",
        "num_labels = len(label_names)\n",
        "\n",
        "means = compute_mean_for_each_label(x_train, y_train, num_labels)\n",
        "\n",
        "print('Features names:', feature_names)\n",
        "for label in range(num_labels):\n",
        "    print(f'Mean {label_names[label]}: {means[label]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2RWR03iKJXp_"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_digit_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "shFPZuIeJXp_"
      },
      "outputs": [],
      "source": [
        "num_labels = len(label_names)\n",
        "\n",
        "means = compute_mean_for_each_label(x_train, y_train, num_labels)\n",
        "\n",
        "for label in range(num_labels):\n",
        "    show_digit(means[label], label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wpLqXlwPJXp_"
      },
      "source": [
        "### Run the local autograder tests for this question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "gpFf91Q6JXp_"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q1b\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mZKQ-YL3JXp_"
      },
      "source": [
        "## Q1c: Nearest mean classification <a class=\"anchor\" name=\"q1c\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8lYwEybVJXqA"
      },
      "source": [
        "Given a list of mean points per label and a new point, predict the label for the new point.\n",
        "\n",
        "1. Find the closest mean by computing the distances from the new point to each mean\n",
        "2. Return the label (index of the list of means) of the closest mean\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/nearest_mean_process.png\" width=\"750\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BeTgAFGgJXqA"
      },
      "source": [
        "### Distance function in higher dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "CBuenaAUJXqA"
      },
      "source": [
        "We may be used to seeing the distance function in 2-D:\n",
        "\n",
        "$$dist\\left(\\mathbf{u}, \\mathbf{v}\\right) = \\sqrt{\\left(u_1 - v_1\\right)^2 + \\left(u_2 - v_2\\right)^2}$$\n",
        "\n",
        "The distance function in 3-D is similarly:\n",
        "\n",
        "$$dist\\left(\\mathbf{u}, \\mathbf{v}\\right) = \\sqrt{\\left(u_1 - v_1\\right)^2 + \\left(u_2 - v_2\\right)^2  + \\left(u_3 - v_3\\right)^2} = \\left(\\sum_{i=1}^3 \\left(u_i - v_i\\right)^2\\right)^\\frac{1}{2}$$\n",
        "\n",
        "The distance function in N-D just continues this pattern:\n",
        "\n",
        "$$dist\\left(\\mathbf{u}, \\mathbf{v}\\right) = \\left(\\sum_{i=1}^N \\left(u_i - v_i\\right)^2\\right)^\\frac{1}{2}$$\n",
        "\n",
        "We can also write this using linear algebra with vector subtraction and the L-2 norm:\n",
        "\n",
        "$$dist\\left(\\mathbf{u}, \\mathbf{v}\\right) = \\left\\|\\mathbf{u} - \\mathbf{v}\\right\\|_2$$\n",
        "\n",
        "where the L-2 norm is defined as $\\left\\|\\mathbf{z}\\right\\|_2 = \\left(\\sum_{i=1}^N {z_i}^2\\right)^\\frac{1}{2}$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "qatouwTuJXqA"
      },
      "source": [
        "### Implement predict_nearest_mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MUnpuZ1sJXqA"
      },
      "source": [
        "<span style=\"color:red\">Note:</span> Looping over the number of labels is acceptable. Other than that, you must use NumPy in these function rather than loops. Points will be taken off during manual grading (autograder would still give full points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKHzZzj3JXqA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# It may be helpful to implement and use this multidimensional dimensional distance function\n",
        "#\n",
        "# Note: We are using the letter M as the number of dimensions (rather than N) to start\n",
        "# getting used to our convention of using M to represent the number of features (of a\n",
        "# single point) and N for the number of data points)\n",
        "def distance(point1, point2):\n",
        "    \"\"\" Return the distance between point1 and point2\n",
        "\n",
        "        Input:\n",
        "        point1: Numpy array with shape (M,)\n",
        "        point2: Numpy array with shape (M,)\n",
        "\n",
        "        Returns: distance as a single number\n",
        "    \"\"\"\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7LirpvwJXqB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def predict_nearest_mean(means_for_each_label, x_new):\n",
        "    \"\"\" Determine which mean in means_for_each_label is closest to x_new\n",
        "        and return the associated label\n",
        "\n",
        "        For example, if the means_for_each_label[2] is the closest to x_new,\n",
        "        then this function should return 2\n",
        "\n",
        "        Input:\n",
        "        means_for_each_label: list of length K, where each entry in the list\n",
        "            is a Numpy array with shape (M,) representing the mean point for\n",
        "            each label class. K is the number of possible labels and M is the\n",
        "            number of features in the data.\n",
        "        x_new: Numpy array with shape (M,)\n",
        "\n",
        "        Returns:\n",
        "        Best label as an integer between 0 and K-1, inclusively\n",
        "    \"\"\"\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DmrM3e3kJXqB"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local tests.\n",
        "\n",
        "Are the results what you expect them to be?\n",
        "\n",
        "Feel free to modify these or add more cells to help you test your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-zBVSo2YJXqB"
      },
      "outputs": [],
      "source": [
        "means = [np.array([0, 0]),\n",
        "         np.array([1, 0]),\n",
        "         np.array([2, 0])]\n",
        "\n",
        "new_point = np.array([0, 1])\n",
        "\n",
        "predicted_label = predict_nearest_mean(means, new_point)\n",
        "predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "vKgPJHIBJXqB"
      },
      "outputs": [],
      "source": [
        "# Visualize the above results\n",
        "plt.figure(figsize=(4,4))\n",
        "plot_mean_points(means, label_names=[0,1,2])\n",
        "plt.plot(new_point[0], new_point[1], 'm*', markersize=10, label=f\"New predicted as {predicted_label}\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "oYC7nRtAJXqB"
      },
      "outputs": [],
      "source": [
        "means = [np.array([0, 0]),\n",
        "         np.array([0, 1]),\n",
        "         np.array([0, 2])]\n",
        "\n",
        "new_point = np.array([1, 2])\n",
        "\n",
        "predicted_label = predict_nearest_mean(means, new_point)\n",
        "predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LMMQn9TEJXqB"
      },
      "outputs": [],
      "source": [
        "# Visualize the above results\n",
        "plt.figure(figsize=(4,4))\n",
        "plot_mean_points(means, label_names=[0,1,2])\n",
        "plt.plot(new_point[0], new_point[1], 'm*', markersize=10, label=f\"New predicted as {predicted_label}\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cxJNpEI2JXqC"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_animals_dataset()\n",
        "\n",
        "# Skip the training and define our own means\n",
        "means = np.array([[13.4,  8.0],\n",
        "       [28.0, 22.9],\n",
        "       [25.5, 10.6],\n",
        "       [10.5,  4.7],\n",
        "       [17.6,  6.4]])\n",
        "\n",
        "# Pick one test point\n",
        "test_index = 0\n",
        "new_point = x_test[test_index]\n",
        "\n",
        "predicted_label = predict_nearest_mean(means, new_point)\n",
        "predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BERDI_31JXqC"
      },
      "outputs": [],
      "source": [
        "# Visualize the above results\n",
        "plt.figure(figsize=(4,4))\n",
        "plot_mean_points(means, label_names)\n",
        "plt.plot(new_point[0], new_point[1], 'm*', markersize=10, label=f\"New predicted as {label_names[predicted_label]}\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "QYFrnLD7JXqC"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset_two_features()\n",
        "\n",
        "# Skip the training and define our own means\n",
        "means = np.array([[5.0, 3.4],\n",
        "                  [5.9, 2.8],\n",
        "                  [6.6, 3.0]])\n",
        "\n",
        "# Pick one test point\n",
        "test_index = 3\n",
        "new_point = x_test[test_index]\n",
        "\n",
        "predicted_label = predict_nearest_mean(means, new_point)\n",
        "predicted_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4cywl1cuJXqC"
      },
      "outputs": [],
      "source": [
        "# Visualize the above results\n",
        "plt.figure(figsize=(4,4))\n",
        "plot_mean_points(means, label_names)\n",
        "plt.plot(new_point[0], new_point[1], 'm*', markersize=10, label=f\"New predicted as {label_names[predicted_label]}\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "csu-wS2rJXqC"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_digit_dataset()\n",
        "\n",
        "means = compute_mean_for_each_label(x_train, y_train, num_labels)\n",
        "\n",
        "# Pick one test point\n",
        "test_index = 0\n",
        "new_point = x_test[test_index]\n",
        "\n",
        "predicted_label = predict_nearest_mean(means, new_point)\n",
        "\n",
        "measured_label = y_test[test_index]\n",
        "\n",
        "show_digit(new_point, y_meas=label_names[measured_label], y_pred=label_names[predicted_label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8dgcQrOuJXqC"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_digit_dataset()\n",
        "\n",
        "means = compute_mean_for_each_label(x_train, y_train, num_labels)\n",
        "\n",
        "# Pick one test point\n",
        "test_index = 1\n",
        "new_point = x_test[test_index]\n",
        "\n",
        "predicted_label = predict_nearest_mean(means, new_point)\n",
        "\n",
        "measured_label = y_test[test_index]\n",
        "\n",
        "show_digit(new_point, y_meas=label_names[measured_label], y_pred=label_names[predicted_label])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "EsjWJDDrJXqD"
      },
      "source": [
        "### Run the local autograder tests for this question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "69BKCvoWJXqD"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q1c\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "__f08hUTJXqD"
      },
      "source": [
        "## Q1d: Classification performance measure <a class=\"anchor\" name=\"q1d\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rN0cVwx7JXqD"
      },
      "source": [
        "Using NumPy here is convenient and good practice, but it isn't required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdMNfG1fJXqD",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def classification_error_rate(y_meas, y_pred):\n",
        "    \"\"\" Calculate the fraction of times the entries the y_meas array differ from the\n",
        "        entries in the y_pred array.\n",
        "\n",
        "        Input:\n",
        "        y_meas: Numpy array with shape (N,)\n",
        "        y_pred: Numpy array with shape (N,)\n",
        "\n",
        "        Return: error rate as a numerical value from 0.0 to 1.0\n",
        "    \"\"\"\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMVdg_snJXqD",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def classification_accuracy(y_meas, y_pred):\n",
        "    \"\"\" Calculate the fraction of times the entries the y_meas array are the same as the\n",
        "        entries in the y_pred array.\n",
        "\n",
        "        Input:\n",
        "        y_meas: Numpy array with shape (N,)\n",
        "        y_pred: Numpy array with shape (N,)\n",
        "\n",
        "        Return: accuracy as a numerical value from 0.0 to 1.0\n",
        "    \"\"\"\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "kvLr9kIIJXqE"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local tests.\n",
        "\n",
        "Are the results what you expect them to be?\n",
        "\n",
        "Feel free to modify these or add more cells to help you test your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "cPCMozXgJXqE"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([0, 0, 0, 0])\n",
        "y_pred = np.array([1, 1, 1, 1])\n",
        "classification_error_rate(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "DvK4jt11JXqE"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([1, 1, 1, 1])\n",
        "y_pred = np.array([1, 1, 1, 1])\n",
        "classification_error_rate(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "jfdY2646JXqE"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([0, 0, 0, 0])\n",
        "y_pred = np.array([1, 1, 1, 1])\n",
        "classification_error_rate(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "i6CGtcAcJXqE"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([1, 1, 1, 1])\n",
        "y_pred = np.array([0, 1, 1, 1])\n",
        "classification_error_rate(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UIQpRCGCJXqE"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([1, 1, 1, 1, 0, 0])\n",
        "y_pred = np.array([1, 1, 0, 1, 1, 1])\n",
        "classification_error_rate(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2-OVhSn2JXqE"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([0, 0, 0, 0])\n",
        "y_pred = np.array([1, 1, 0, 1])\n",
        "classification_error_rate(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "N9-Qp3wLJXqF"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([0, 0, 0, 0])\n",
        "y_pred = np.array([1, 1, 0, 1])\n",
        "classification_accuracy(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "JqeKIcvaJXqF"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([0, 0, 0, 0])\n",
        "y_pred = np.array([0, 0, 0, 0])\n",
        "classification_accuracy(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9UtjxzHmJXqF"
      },
      "outputs": [],
      "source": [
        "y_meas = np.array([2, 2, 0, 1])\n",
        "y_pred = np.array([2, 0, 4, 2])\n",
        "classification_accuracy(y_meas, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "x8BOlcgGJXqF"
      },
      "source": [
        "### Run the local autograder tests for this question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hINHlNfkJXqF"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q1d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "u4aRwQcDJXqF"
      },
      "source": [
        "## Q1e Putting it all together <a class=\"anchor\" name=\"q1e\"></a>"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Ah6ZFNGoJXqF"
      },
      "source": [
        "Looping over points your predict_all helper function is acceptable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fmUYAj3vJXqG"
      },
      "source": [
        "### Provided functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GguhuJP8JXqG"
      },
      "source": [
        "The `model = train(x_train, y_train, num_labels)` function has been provided for you.\n",
        "\n",
        "We recommend that you look at this function to see exactly what we mean by \"train\" in this context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_joAumg5JXqG"
      },
      "outputs": [],
      "source": [
        "# Given\n",
        "# Do NOT change\n",
        "def train(x_train, y_train, num_labels):\n",
        "    \"\"\" Use training data x_train and y_train to train a nearest mean model.\n",
        "        The returned model is simply a list of means, one for each label.\n",
        "\n",
        "        Input:\n",
        "        x_train: Numpy array with shape (N, M) where the rows are filled with N M-dimensional data points\n",
        "        y_train: Numpy array with shape (N,) The label value for each of the N points in x_train\n",
        "\n",
        "        Returns: Return a list of length num_labels, where i-th entry in the list is a Numpy array with\n",
        "                 shape (M,) containing the mean of datapoints in x_train with label equal to i.\n",
        "    \"\"\"\n",
        "    means_for_each_label = compute_mean_for_each_label(x_train, y_train, num_labels)\n",
        "\n",
        "    return means_for_each_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "9DgTTv3fJXqG"
      },
      "source": [
        "### Implement train_predict_and_measure_performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAVRJTV8JXqG",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Helper function to predict many points\n",
        "# A loop over points is acceptible here\n",
        "def predict_all(means_for_each_label, x_data):\n",
        "    \"\"\" For each input point in x_data, predict the output label y using\n",
        "        predict_nearest_mean and the provided list of means for each label\n",
        "\n",
        "        Input:\n",
        "        means_for_each_label: a list of length K, where each entry in the list\n",
        "            is a Numpy array with shape (M,) representing the mean point for\n",
        "            each label class. K is the number of possible labels and M is the\n",
        "            number of features in the data.\n",
        "        x_data: Numpy array with shape (N, M) where the rows are filled with N M-dimensional data points\n",
        "\n",
        "        Returns: Return Numpy array with shape (N,) The predicted label value for each of the N points in x_data\n",
        "    \"\"\"\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I5r-1ReJXqG",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train_predict_and_measure_performance(x_train, y_train, x_test, y_test, label_names, feature_names):\n",
        "    \"\"\" Put all the steps together to create and evaluate a machine learning system\n",
        "\n",
        "        1. Given the training data x_train and y_train, train your nearest neighbor model\n",
        "        2. Compute the classification accuracy on the training data\n",
        "        3. Compute the classification accuracy on the test data\n",
        "\n",
        "        Input:\n",
        "        x_train: Numpy array with shape (N_train, M) where the rows are filled with N_train M-dimensional data points\n",
        "        y_train: Numpy array with shape (N_train,). The label value for each of the N_train points in x_train\n",
        "        x_test: Numpy array with shape (N_test, M) where the rows are filled with N_test M-dimensional data points\n",
        "        y_test: Numpy array with shape (N_test,). The label value for each of the N_test points in x_test\n",
        "        label_names: list of strings where the i-th string is the label name for class i. This is only\n",
        "                     used for plotting\n",
        "        feature_names: list of strings where the i-th string is the feature name for the i-th features. This is only\n",
        "                       used for plotting\n",
        "\n",
        "        Returns: (training_accuracy, testing_accuracy). These two values are both numbers between\n",
        "                 zero and one (they could also be exactly zero or one).\n",
        "    \"\"\"\n",
        "\n",
        "    ...\n",
        "\n",
        "\n",
        "    # Code to plot data and means. You can use this to visualize data and/or debug.\n",
        "    # Uncomment the code below to use it\n",
        "    #\n",
        "    # Note the variable \"means\" is not defined. You would have to define it above if\n",
        "    # you want to use it.\n",
        "\n",
        "    # Plotting the data only really makes sense if you only two features\n",
        "#     if len(feature_names) == 2:\n",
        "#         plot_labeled_points(x_train, y_train, label_names, feature_names)\n",
        "#         plot_mean_points(means, label_names, feature_names)\n",
        "\n",
        "\n",
        "    # Don't forget to return the training and testing accuracy\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "V19qAtq4JXqH"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local tests.\n",
        "\n",
        "Feel free to modify these or add more cells to help you test your code.\n",
        "\n",
        "Change the dataset to see if your code works for all of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Sk-mu5x_JXqH"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_animals_dataset()\n",
        "# x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset_two_features()\n",
        "# x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset()\n",
        "# x_train, y_train, x_test, y_test, label_names, feature_names = load_digit_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fHILoYC1JXqH"
      },
      "outputs": [],
      "source": [
        "train_accuracy, test_accuracy = train_predict_and_measure_performance(x_train, y_train, x_test, y_test, label_names, feature_names)\n",
        "\n",
        "print('Performance on training dataset:')\n",
        "print(f'    accuracy: {train_accuracy: 0.3f}')\n",
        "\n",
        "print('Performance on test dataset:')\n",
        "print(f'    accuracy: {test_accuracy: 0.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "rVlRg3PcJXqH"
      },
      "source": [
        "### Run the local autograder tests for this question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Qf5INa45JXqH"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q1e\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8durn2KYJXqH"
      },
      "source": [
        "## Q1f Exploring results <a class=\"anchor\" name=\"q1f\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "NnoXOUDOJXqH"
      },
      "source": [
        "One of the most import skills used to improve your machine learning models in practice is to explore the predicted results of your model. It is particularly useful to look at the examples that your model got wrong."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1SZ4ooFFJXqI"
      },
      "source": [
        "Using a for loop over test points is acceptable here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56wU-jLyJXqI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def find_first_misclassified_datapoint(means_for_each_label, x_test, y_test, correct_label):\n",
        "    \"\"\" Loop through the test data points in order and return the index\n",
        "        of the first test point that you find where the true label is\n",
        "        correct_label but your nearest means function predicts some other\n",
        "        label.\n",
        "\n",
        "        You have already been given the means for each label, so there is no need\n",
        "        to train your model.\n",
        "\n",
        "        For example, return the number 10 if 10 is the first index where both\n",
        "        of the following are true:\n",
        "        -- y_test[10] is the same as correct_label\n",
        "        -- The predicted label for input x_test[10] does not equal y_test[10]\n",
        "\n",
        "        Input:\n",
        "        means_for_each_label: a list Numpy array means, where i-th entry in the list is a Numpy array with\n",
        "                shape (M,) containing the mean of datapoints with label equal to i. The length of the\n",
        "                list corresponds to the number of possible labels.\n",
        "\n",
        "        x_test: Numpy array with shape (N, M) where the rows are filled with N M-dimensional data points\n",
        "        y_test: Numpy array with shape (N,). The label value for each of the N points in x_test\n",
        "        correct_label: The label that you want to find the first misclassified point for. This is an integer\n",
        "                       between 0 and K-1, inclusively, where K is the number of possible labels.\n",
        "\n",
        "        Return: first_index, y_pred. Where first_index is the integer index for the first incorrectly\n",
        "                classified data point with the correct label equal to correct_label and y_pred is your\n",
        "                predicted label for input x_test[first_index].\n",
        "                Return (-1, -1) if all points with the correct label equal to correct_label are classified\n",
        "                correctly.\n",
        "    \"\"\"\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzKRuUoUJXqI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_animals_dataset()\n",
        "means = train(x_train, y_train, len(label_names))\n",
        "\n",
        "# Find the first datapoint the was incorrectly predicted as a Beaver (label 1)\n",
        "correct_label = 1\n",
        "correct_label_name = label_names[correct_label] # Beaver\n",
        "\n",
        "first_index, y_pred = find_first_misclassified_datapoint(means, x_test, y_test, correct_label)\n",
        "\n",
        "if first_index == -1:\n",
        "    print(f\"Could not find a misclassified point for correct label {correct_label}\")\n",
        "else:\n",
        "    print(f\"Test point {first_index} should be {label_names[correct_label]} but was predicted to be {label_names[y_pred]}.\")\n",
        "\n",
        "    plt.figure(figsize=(4,4))\n",
        "    plot_mean_points(means, label_names, feature_names)\n",
        "    plt.plot(x_test[first_index, 0], x_test[first_index,1], 'kx', markersize=8, markeredgewidth=2, label=f\"Error {first_index}\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b6GuRGcJXqI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_animals_dataset()\n",
        "means = train(x_train, y_train, len(label_names))\n",
        "\n",
        "for correct_label in range(len(label_names)):\n",
        "    first_index, y_pred = find_first_misclassified_datapoint(means, x_test, y_test, correct_label)\n",
        "    if first_index == -1:\n",
        "        print(f\"Could not find a misclassified point for correct label {correct_label}\")\n",
        "    else:\n",
        "        print(f\"Test point {first_index} should be {label_names[correct_label]} but was predicted to be {label_names[y_pred]}.\")\n",
        "\n",
        "        plt.figure(figsize=(4,4))\n",
        "        plot_mean_points(means, label_names, feature_names)\n",
        "        plt.plot(x_test[first_index, 0], x_test[first_index,1], 'kx', markersize=8, markeredgewidth=2, label=f\"Error {first_index}\")\n",
        "        plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmVDHpQzJXqI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_iris_dataset_two_features()\n",
        "means = train(x_train, y_train, len(label_names))\n",
        "\n",
        "for correct_label in range(len(label_names)):\n",
        "    first_index, y_pred = find_first_misclassified_datapoint(means, x_test, y_test, correct_label)\n",
        "    if first_index == -1:\n",
        "        print(f\"Could not find a misclassified point for correct label {correct_label}\")\n",
        "    else:\n",
        "        print(f\"Test point {first_index} should be {label_names[correct_label]} but was predicted to be {label_names[y_pred]}.\")\n",
        "\n",
        "        plt.figure(figsize=(4,4))\n",
        "        plot_mean_points(means, label_names, feature_names)\n",
        "        plt.plot(x_test[first_index, 0], x_test[first_index,1], 'kx', markersize=8, markeredgewidth=2, label=f\"Error {first_index}\")\n",
        "        plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8KaOK7CJXqI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_digit_dataset()\n",
        "means = train(x_train, y_train, len(label_names))\n",
        "\n",
        "for correct_label in range(len(label_names)):\n",
        "    first_index, y_pred = find_first_misclassified_datapoint(means, x_test, y_test, correct_label)\n",
        "    if first_index == -1:\n",
        "        print(f\"Could not find a misclassified point for correct label {correct_label}\")\n",
        "    else:\n",
        "        print(f\"Test point {first_index} should be {label_names[correct_label]} but was predicted to be {label_names[y_pred]}.\")\n",
        "\n",
        "        show_digit(x_test[first_index], correct_label, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "RAQtwsQTJXqJ"
      },
      "source": [
        "### Run the local autograder tests for this question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4t2ZKkTzJXqJ"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q1f\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZA3dXqvJXqJ"
      },
      "source": [
        "### Links back to questions\n",
        "\n",
        "* [Q0: Autograder introduction](#q0)\n",
        "* [Q1a: Computing the mean](#q1a)\n",
        "* [Q1b: Compute the mean for each label](#q1b)\n",
        "* [Q1c: Nearest mean classification](#q1c)\n",
        "* [Q1d: Classification performance measure](#q1d)\n",
        "* [Q1e: Putting it all together](#q1e)\n",
        "* [Q1f: Exploring results](#q1f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqGcyCnWJXqJ"
      },
      "source": [
        "# Question 2: Neural Networks <a class=\"anchor\" name=\"q2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz84fjLTJXqJ"
      },
      "source": [
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/digit_network_summary.png\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO9uatlzJXqJ"
      },
      "source": [
        "## Q2 Table of Contents\n",
        "\n",
        "* [Q2a: Three neuron network](#q2a)\n",
        "* [Q2b: 28x28 image classification network](#q2b)\n",
        "* [Q2c: 28x28 image autoencoder network](#q2c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4w7z-ZaJXqJ"
      },
      "source": [
        "## Q2 Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRMkUGFKJXqK"
      },
      "source": [
        "Neural networks are made up of layers of neurons that transform the input data into a predicted output.\n",
        "\n",
        "In this question, we'll wire up two different neural networks: a three neuron (7 parameter) network to predict the intensity of Minneapolis traffic given the time of day (below) and a 210 neuron (159,010 parameter) network to predict the class label of a 28x28 input image (above).\n",
        "\n",
        "Results of three neuron network:\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/traffic_data_network_summary.png\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Qsq0I5AXJXqK"
      },
      "source": [
        "## Q2a: Three-neuron network <a class=\"anchor\" name=\"q2a\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LvQDZUBfJXqK"
      },
      "source": [
        "Implement the `network3` function to match the following three-neuron network diagram, where ReLU function is simply the max of zero and the input, $a = \\max(0, z)$:\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/three_neuron_diagram.png\" width=\"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "GcuiNLQWJXqK"
      },
      "source": [
        "Note: These are all scalar values, not vectors or matrices.\n",
        "\n",
        "No need for NumPy here. We'll get to that in a second!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7mEQxJUJXqK",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def network3(x, wA, bA, wB, bB, wC, wD, bC):\n",
        "    \"\"\" Compute the predicted output y given the input x and the network parameters\n",
        "        Note: These are all scalar values\n",
        "\n",
        "        Input:\n",
        "        x: numerical value of the input\n",
        "        wA: numerical value of the weight from the input to the first neuron in the hidden layer\n",
        "        bA: numerical value of the bias associated with the first neuron in the hidden layer\n",
        "        wB: numerical value of the weight from the input to the second neuron in the hidden layer\n",
        "        bB: numerical value of the bias associated with the second neuron in the hidden layer\n",
        "        wC: numerical value of the weight from the first neuron in the hidden layer to the output neuron\n",
        "        wD: numerical value of the weight from the second neuron in the hidden layer to the output neuron\n",
        "        bC: numerical value of the bias associated with the output neuron\n",
        "\n",
        "        Returns: numerical value of the predicted output\n",
        "    \"\"\"\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "NgfUCHvwJXqK"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local tests.\n",
        "\n",
        "Are the results what you expect them to be?\n",
        "\n",
        "Feel free to modify these or add more cells to help you test your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "MVqwpH-9JXqK"
      },
      "outputs": [],
      "source": [
        "wA = 1\n",
        "bA = 0\n",
        "wB = 0\n",
        "bB = 0\n",
        "wC = 1\n",
        "wD = 1\n",
        "bC = 0\n",
        "\n",
        "x_new = 8\n",
        "y_new_pred = network3(x_new, wA, bA, wB, bB, wC, wD, bC)\n",
        "\n",
        "plot_network_prediction(None, None, x_new,\n",
        "                        network3, wA, bA, wB, bB, wC, wD, bC,\n",
        "                        x_label=\"Input\", y_label=\"Output\",\n",
        "                        x_min=-10, x_max=10)\n",
        "y_new_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fRqCc0xkJXqL"
      },
      "outputs": [],
      "source": [
        "wA = 0\n",
        "bA = 0\n",
        "wB = 1\n",
        "bB = 0\n",
        "wC = 1\n",
        "wD = 1\n",
        "bC = 0\n",
        "\n",
        "x_new = -8\n",
        "y_new_pred = network3(x_new, wA, bA, wB, bB, wC, wD, bC)\n",
        "\n",
        "plot_network_prediction(None, None, x_new,\n",
        "                        network3, wA, bA, wB, bB, wC, wD, bC,\n",
        "                        x_label=\"Input\", y_label=\"Output\",\n",
        "                        x_min=-10, x_max=10)\n",
        "y_new_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UfKMX9VKJXqL"
      },
      "outputs": [],
      "source": [
        "wA = 1\n",
        "bA = -5\n",
        "wB = -2\n",
        "bB = 5\n",
        "wC = 1\n",
        "wD = -1\n",
        "bC = 10\n",
        "\n",
        "x_new = -8\n",
        "y_new_pred = network3(x_new, wA, bA, wB, bB, wC, wD, bC)\n",
        "\n",
        "plot_network_prediction(None, None, x_new,\n",
        "                        network3, wA, bA, wB, bB, wC, wD, bC,\n",
        "                        x_label=\"Input\", y_label=\"Output\",\n",
        "                        x_min=-10, x_max=10)\n",
        "y_new_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hkVNHnZrJXqL"
      },
      "outputs": [],
      "source": [
        "#@title Draw custom inputs { run: \"auto\"}\n",
        "wA = 1 #@param {type:\"slider\", min:-5, max:5, step:0.1}\n",
        "bA = 0 #@param {type:\"slider\", min:-10, max:10, step:0.1}\n",
        "wB = -1 #@param {type:\"slider\", min:-5, max:5, step:0.1}\n",
        "bB = 0 #@param {type:\"slider\", min:-10, max:10, step:0.1}\n",
        "wC = 1 #@param {type:\"slider\", min:-5, max:5, step:0.1}\n",
        "wD = 1 #@param {type:\"slider\", min:-5, max:5, step:0.1}\n",
        "bC = 0 #@param {type:\"slider\", min:-10, max:10, step:0.1}\n",
        "x_new = 0  #@param {type:\"slider\", min:-10, max:10, step:0.5}\n",
        "\n",
        "y_new_pred = network3(x_new, wA, bA, wB, bB, wC, wD, bC)\n",
        "\n",
        "plot_network_prediction(None, None, x_new,\n",
        "                        network3, wA, bA, wB, bB, wC, wD, bC,\n",
        "                        x_label=\"Input\", y_label=\"Output\",\n",
        "                        x_min=-10, x_max=10)\n",
        "y_new_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bdXYHbDpJXqL"
      },
      "outputs": [],
      "source": [
        "# Load the traffic dataset\n",
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_traffic_dataset()\n",
        "\n",
        "wA = 0.4\n",
        "bA = -5.9\n",
        "wB = -0.6\n",
        "bB = 5.2\n",
        "wC = -1\n",
        "wD = -1\n",
        "bC = 5.1\n",
        "\n",
        "x_new = 8\n",
        "y_new_pred = network3(x_new, wA, bA, wB, bB, wC, wD, bC)\n",
        "\n",
        "plot_network_prediction(x_train, y_train, x_new,\n",
        "                        network3, wA, bA, wB, bB, wC, wD, bC)\n",
        "y_new_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "o8SoW7gZJXqL"
      },
      "source": [
        "### Run the local autograder tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "u_lwe61aJXqL"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q2a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ce0g3BtJXqL"
      },
      "source": [
        "### Again, remember to keep submitting to Gradescope as you go.\n",
        "\n",
        "This will help you to make sure you are passing the hidden tests as well as the local tests. It also is a good reminder to save your work and make sure you officially collect points in Gradescope. You wouldn't want to finish all of your work and then realize at the last minute that there was something wrong with Q1 that caused problems for your whole assignment in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "m18VYZp_JXqM"
      },
      "source": [
        "## Q2b: 28x28 Image Classification Network <a class=\"anchor\" name=\"q2b\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "QIkc06bJJXqM"
      },
      "source": [
        "In this question, we'll implement a two-layer neural network that will be able to classify 28x28 hand-written digits with 96% accuracy.\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/digit_network_summary.png\" width=\"600\"/>\n",
        "\n",
        "As a quick preview, the network function that you will implement is: `network(x, layer1_w, layer1_b, layer2_w, layer2_b)`, which will take in the input image, `x`, and return 10 values indicating the strength of the prediction for each class, a value for 0-9 in the case of digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hOufph0-JXqM"
      },
      "source": [
        "### Scaling up our network implementation using linear algebra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "7C4tR4FIJXqM"
      },
      "source": [
        "Notice that in our original three neuron network, there are actually multiple linear functions: two with a 1-D input and one with a 2-D input.\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/three_neuron_diagram.png\" width=\"800\"/>\n",
        "\n",
        "It would be really nice if we could use linear algebra to generalize these as linear functions with multiple inputs and multiple outputs:\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/three_neuron_diagram_layers.png\" width=\"800\"/>\n",
        "\n",
        "The diagram above is now a network that is exactly the same diagram for our three neuron network and for the digit classification network below! The only difference is in the size various vectors and matrices involved. For the digit classification network, here are the sizes:\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\mathbf{x} &\\in \\mathbb{R}^{784} &\n",
        "W_1 &\\in \\mathbb{R}^{200\\times 784} &\n",
        "\\mathbf{z} &\\in \\mathbb{R}^{200} &\n",
        "\\mathbf{a} &\\in \\mathbb{R}^{200} &\n",
        "W_2 &\\in \\mathbb{R}^{10\\times 200} &\n",
        "\\mathbf{y}_{pred} &\\in \\mathbb{R}^{10} \\\\\n",
        "& &\n",
        "\\mathbf{b}_1 &\\in \\mathbb{R}^{200} &\n",
        "& &\n",
        "& &\n",
        "\\mathbf{b}_2 &\\in \\mathbb{R}^{10} &\n",
        "\\end{align*}$$\n",
        "\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/digit_network_summary.png\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zF7gLrA6JXqM"
      },
      "source": [
        "### Parameters: Weights and biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-FdclIrZJXqM"
      },
      "source": [
        "We've already trained this image classification network using PyTorch: https://www.kaggle.com/code/justuser/mnist-with-pytorch-fully-connected-network/notebook We've saved the resulting weight (W) and bias (b) values for both linear layers.\n",
        "\n",
        "We'll pass these weights (W) and biases (b) into your `network(x, linear1_w, linear1_b, linear2_w, linear2_b)` function.\n",
        "\n",
        "For the pretrained network we've stored these weights and bias values in \\*.csv files:\n",
        "- http://cs.cmu.edu/~10315/data/mnist_layer1_weights.csv\n",
        "- http://cs.cmu.edu/~10315/data/mnist_layer1_biases.csv\n",
        "- http://cs.cmu.edu/~10315/data/mnist_layer2_weights.csv\n",
        "- http://cs.cmu.edu/~10315/data/mnist_layer2_biases.csv\n",
        "\n",
        "<!-- We'll then read those \\*.csv files into NumPy arrays using `np.loadtxt(filename, delimiter=',')`. The format of these NumPy arrays will be as follows:\n",
        "\n",
        "#### Layer 1 weights\n",
        "Shape: (200, 784)\n",
        "\n",
        "The *first* row of this weight array contains the 784 weights to be applied to the 784 input pixels for the *first* neuron in layer 1.\n",
        "\n",
        "The *k-th* row of this weight array contains the 784 weights to be applied to the 784 input pixels for the *k-th* neuron in layer 1.\n",
        "\n",
        "#### Layer 1 bias\n",
        "Shape: (200,)\n",
        "\n",
        "The *first* value in this 1-D array contains the bias value to be applied to the *first* neuron in layer 1.\n",
        "\n",
        "The *k-th* value in this 1-D array contains the bias value to be applied to the *k-th* neuron in layer 1.\n",
        "\n",
        "#### Layer 2 weights\n",
        "Shape: (10, 200)\n",
        "\n",
        "The *first* row of this weight array contains the 200 weights to be applied to the 200 input values for the *first* neuron in layer 2.\n",
        "\n",
        "The *k-th* row of this weight array contains the 200 weights to be applied to the 200 input values for the *k-th* neuron in layer 2.\n",
        "\n",
        "#### Layer 2 bias\n",
        "Shape: (10,)\n",
        "\n",
        "The *first* value in this 1-D array contains the bias value to be applied to the *first* neuron in layer 2.\n",
        "\n",
        "The *k-th* value in this 1-D array contains the bias value to be applied to the *k-th* neuron in layer 2. -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "ZT05_3pwJXqN"
      },
      "source": [
        "### Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fHlz1hcNJXqN"
      },
      "source": [
        "<span style=\"color:red\">Note:</span> You must use NumPy in these functions; no loops allowed. Points will be taken off during manual grading (autograder would still give full points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leTxF3ZnJXqN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def linear(x, W, b):\n",
        "    \"\"\" Generic linear layer where the input x is the input vector to this layer (note: not necessarily\n",
        "        the input to the whole network, which we also tend to call x).\n",
        "        Input:\n",
        "        x: Numpy array with shape (num_in,)\n",
        "        W: Numpy array with shape (num_out, num_in)\n",
        "        b: Numpy array with shape (num_out,)\n",
        "\n",
        "        Returns: Numpy array with shape (num_out,)\n",
        "    \"\"\"\n",
        "\n",
        "    ...\n",
        "\n",
        "def relu(z):\n",
        "    \"\"\" ReLU (rectified linear unit) that returns the max of zero and the input value for each entry\n",
        "        input vector.\n",
        "        Input:\n",
        "        z: Numpy array with shape (num_in,)\n",
        "\n",
        "        Returns: Numpy array with shape (num_in,)\n",
        "    \"\"\"\n",
        "\n",
        "    ...\n",
        "\n",
        "def network(x, linear1_w, linear1_b, linear2_w, linear2_b):\n",
        "    \"\"\" Return the result of passing input values x through neural network given the weight and bias parameters\n",
        "        for the two linear layers.\n",
        "\n",
        "        Input:\n",
        "        x: Numpy array with shape (784,)\n",
        "        linear1_w: Numpy array with shape (200, 784) containing the weights for linear layer 1\n",
        "        linear1_b: Numpy array with shape (200,) containing the bias values for linear layer 1\n",
        "        linear_w: Numpy array with shape (10, 200) containing the weights for linear layer 2\n",
        "        linear2_b: Numpy array with shape (10,) containing the bias values for linear layer 2\n",
        "\n",
        "        Returns: Numpy array with shape (10,) containing the output of linear layer 2\n",
        "    \"\"\"\n",
        "\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "LJYnntYIJXqN"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local tests.\n",
        "\n",
        "Are the results what you expect them to be?\n",
        "\n",
        "Feel free to modify these or add more cells to help you test your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "44tjCjiUJXqN"
      },
      "source": [
        "Let's jump right in and test with digits. There are some simpler test cases below to help you debug anything that might be going wrong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AxgeqdYZJXqN"
      },
      "outputs": [],
      "source": [
        "# This will take a minute or so the first time you run it\n",
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_digit_dataset()\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "KpU-qHN1JXqN"
      },
      "outputs": [],
      "source": [
        "layer1_weights = np.loadtxt(\"http://cs.cmu.edu/~10315/data/mnist_layer1_weights.csv\", delimiter=',')\n",
        "layer1_biases = np.loadtxt(\"http://cs.cmu.edu/~10315/data/mnist_layer1_biases.csv\", delimiter=',')\n",
        "layer2_weights = np.loadtxt(\"http://cs.cmu.edu/~10315/data/mnist_layer2_weights.csv\", delimiter=',')\n",
        "layer2_biases = np.loadtxt(\"http://cs.cmu.edu/~10315/data/mnist_layer2_biases.csv\", delimiter=',')\n",
        "print(layer1_weights.shape)\n",
        "print(layer1_biases.shape)\n",
        "print(layer2_weights.shape)\n",
        "print(layer2_biases.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "1DIdFhocJXqO"
      },
      "source": [
        "Output for the fifth image in the test set (index = 4):\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/digit_network_output_4.png\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BLNeQ3bfJXqO"
      },
      "outputs": [],
      "source": [
        "# For the fifth image in the test input (index = 4), the output should be the same as the bar chart in the\n",
        "# figure above\n",
        "image_index = 4\n",
        "output = network(x_test[image_index], layer1_weights, layer1_biases, layer2_weights, layer2_biases)\n",
        "\n",
        "show_digit(x_test[image_index])\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(range(10), output)\n",
        "plt.xticks(range(10))\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "s8fwcY3iJXqO"
      },
      "outputs": [],
      "source": [
        "# Running on a range of test images\n",
        "for image_index in range(5):\n",
        "    output = network(x_test[image_index], layer1_weights, layer1_biases, layer2_weights, layer2_biases)\n",
        "\n",
        "    show_digit(x_test[image_index])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.bar(range(10), output)\n",
        "    plt.xticks(range(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "IXrlja9bJXqO"
      },
      "outputs": [],
      "source": [
        "# Test with really simple values to make sure the network functions are working\n",
        "# Output should be all zeros\n",
        "\n",
        "x = np.zeros(784)\n",
        "layer1_weights = np.zeros((200, 784))\n",
        "layer1_biases = np.zeros(200)\n",
        "layer2_weights = np.zeros((10, 200))\n",
        "layer2_biases = np.zeros(10)\n",
        "\n",
        "output = network(x, layer1_weights, layer1_biases, layer2_weights, layer2_biases)\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(range(10), output)\n",
        "plt.xticks(range(10))\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "K85qyXjcJXqO"
      },
      "outputs": [],
      "source": [
        "# Test with really simple values to make sure the network functions are working\n",
        "\n",
        "x = np.zeros(784)\n",
        "layer1_weights = np.zeros((200, 784))\n",
        "layer1_biases = np.zeros(200)\n",
        "layer2_weights = np.zeros((10, 200))\n",
        "layer2_biases = np.arange(10)\n",
        "\n",
        "output = network(x, layer1_weights, layer1_biases, layer2_weights, layer2_biases)\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(range(10), output)\n",
        "plt.xticks(range(10))\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "u9mRyAs5JXqO"
      },
      "outputs": [],
      "source": [
        "# Test with really simple values to make sure the network functions are working\n",
        "# Should have the same results as above because the layer 2 weights are all still zero\n",
        "\n",
        "x = np.zeros(784)\n",
        "layer1_weights = np.random.normal(size=(200, 784))\n",
        "layer1_biases = np.random.normal(size=200)\n",
        "layer2_weights = np.zeros((10, 200))\n",
        "layer2_biases = np.arange(10)\n",
        "\n",
        "output = network(x, layer1_weights, layer1_biases, layer2_weights, layer2_biases)\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(range(10), output)\n",
        "plt.xticks(range(10))\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "NrbsnfMTJXqP"
      },
      "outputs": [],
      "source": [
        "# Test with really simple values to make sure the network functions are working\n",
        "\n",
        "x = 99*np.ones(784)\n",
        "layer1_weights = np.zeros((200, 784))\n",
        "layer1_biases = np.arange(200)\n",
        "layer2_weights = np.zeros((10, 200))\n",
        "for i in range(10):\n",
        "    layer2_weights[i, i] = -2\n",
        "layer2_biases = np.zeros(10)\n",
        "\n",
        "output = network(x, layer1_weights, layer1_biases, layer2_weights, layer2_biases)\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(range(10), output)\n",
        "plt.xticks(range(10))\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UgOKjA1AJXqP"
      },
      "outputs": [],
      "source": [
        "# Test with really simple values to make sure the network functions are working\n",
        "\n",
        "x = 10*np.arange(784)\n",
        "layer1_weights = np.zeros((200, 784))\n",
        "layer1_weights[33, 99] = 1\n",
        "layer1_biases = np.zeros(200)\n",
        "layer2_weights = np.zeros((10, 200))\n",
        "layer2_weights[4, 33] = 1\n",
        "layer2_biases = np.zeros(10)\n",
        "\n",
        "output = network(x, layer1_weights, layer1_biases, layer2_weights, layer2_biases)\n",
        "\n",
        "plt.figure()\n",
        "plt.bar(range(10), output)\n",
        "plt.xticks(range(10))\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "AOWaqsn1JXqP"
      },
      "source": [
        "### Run the local autograder tests for this question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "iDB34CZmJXqP"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q2b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLB6-gcSJXqP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HM0XV-a8JXqP"
      },
      "source": [
        "## Q2c: 28x28 Image Autoencoder Network <a class=\"anchor\" name=\"q2c\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5BsccEC6JXqP"
      },
      "source": [
        "Let's keep going and create an autoencoder network to encode and decode images!\n",
        "\n",
        "<img src=\"https://www.cs.cmu.edu/~10315/figures/autoencoder_network_summary.png\" width=\"800\"/>\n",
        "\n",
        "As a quick preview, you will implement two autoencoder network functions: `encode(x, W1, b1, W2, b2, W3, b3, W4, b4)` and `decode(z, W5, b5, W6, b6, W7, b7, W8, b8)`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "BtBVg8YtJXqP"
      },
      "source": [
        "### Parameters: Weights and biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "yM4E2P4hJXqQ"
      },
      "source": [
        "We've already trained this autoencoder network using PyTorch: https://github.com/L1aoXingyu/pytorch-beginner/blob/master/08-AutoEncoder/simple_autoencoder.py The only modification to the network was changing the dimension from the encoded features to be 2 rather than 3.\n",
        "\n",
        "We've saved the resulting weight (W) and bias (b) values for all 8 linear layers.\n",
        "\n",
        "We'll pass these weights (W) and biases (b) into your `encode` and `decode` functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TahWq9ajJXqQ"
      },
      "source": [
        "The NumPy arrays should have been automatically downloaded and extracted to `autoencoder/*.npy` as part of the setup cell that processed `hw1_additional_files.zip`.\n",
        "\n",
        "Rather than storing these arrays in csv files, we stored them more efficiently in NumPys *.npy files that can be processed with `np.save` and `np.load`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "iYe1s5mmJXqQ"
      },
      "outputs": [],
      "source": [
        "# Loading the weights and biases into a dictonary for convenient storage\n",
        "# This may take a few seconds\n",
        "params = {}\n",
        "for i in range(1, 9):\n",
        "    params[f'W{i}'] = np.load(f'autoencoder/autoencoder_W{i}.npy')\n",
        "    params[f'b{i}'] = np.load(f'autoencoder/autoencoder_b{i}.npy')\n",
        "\n",
        "for key in params:\n",
        "    print(key, params[key].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "FHoeQqxyJXqQ"
      },
      "source": [
        "### Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "gfgloXLaJXqQ"
      },
      "source": [
        "You've already written the `linear` and `relu` functions that should work perfectly well in your autoencoder `encode` and `decode` functions. The only new layer type is a `tanh` layer that, like relu, applies the tanh trig function to each element in the input vector.\n",
        "\n",
        "<span style=\"color:red\">Note:</span> You must use NumPy in these functions; no loops allowed. Points will be taken off during manual grading (autograder would still give full points)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDunN7VCJXqQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "def tanh(z):\n",
        "    \"\"\" tanh function applied to each entry of the input vector.\n",
        "        Input:\n",
        "        z: Numpy array with shape (num_in,)\n",
        "\n",
        "        Returns: Numpy array with shape (num_in,)\n",
        "    \"\"\"\n",
        "\n",
        "    ...\n",
        "\n",
        "def encode(x, W1, b1, W2, b2, W3, b3, W4, b4):\n",
        "    \"\"\" Return the result of passing input values x through the encoder half of the autoencoder network\n",
        "        given the weight and bias parameters for the four encoder linear layers.\n",
        "\n",
        "        Input:\n",
        "        x: Numpy array with shape (784,)\n",
        "        W1: Numpy array with shape (128, 784) containing the weights for linear layer 1\n",
        "        b1: Numpy array with shape (128,) containing the bias values for linear layer 1\n",
        "        W2: Numpy array with shape (64, 128) containing the weights for linear layer 2\n",
        "        b2: Numpy array with shape (64,) containing the bias values for linear layer 2\n",
        "        W3: Numpy array with shape (12, 64) containing the weights for linear layer 2\n",
        "        b3: Numpy array with shape (12,) containing the bias values for linear layer 2\n",
        "        W4: Numpy array with shape (2, 12) containing the weights for linear layer 2\n",
        "        b4: Numpy array with shape (2,) containing the bias values for linear layer 2\n",
        "\n",
        "        Returns: Numpy array with shape (2,) containing the output of encoder half of the network\n",
        "    \"\"\"\n",
        "\n",
        "    ...\n",
        "\n",
        "\n",
        "def decode(z, W5, b5, W6, b6, W7, b7, W8, b8):\n",
        "    \"\"\" Return the result of passing encoded vector z through the decoder half of the autoencoder network\n",
        "        given the weight and bias parameters for the four decoder linear layers.\n",
        "\n",
        "        Input:\n",
        "        z: Numpy array with shape (2,)\n",
        "        W5: Numpy array with shape (12, 2) containing the weights for linear layer 1\n",
        "        b5: Numpy array with shape (12,) containing the bias values for linear layer 1\n",
        "        W6: Numpy array with shape (64, 12) containing the weights for linear layer 2\n",
        "        b6: Numpy array with shape (64,) containing the bias values for linear layer 2\n",
        "        W7: Numpy array with shape (128, 64) containing the weights for linear layer 2\n",
        "        b7: Numpy array with shape (128,) containing the bias values for linear layer 2\n",
        "        W8: Numpy array with shape (784, 128) containing the weights for linear layer 2\n",
        "        b8: Numpy array with shape (784,) containing the bias values for linear layer 2\n",
        "\n",
        "        Returns: Numpy array with shape (784,) containing the output of decoder half of the network\n",
        "    \"\"\"\n",
        "\n",
        "    ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "OLcH_58AJXqQ"
      },
      "source": [
        "Cells that you can run to make sure your code is working before running the local tests.\n",
        "\n",
        "Are the results what you expect them to be?\n",
        "\n",
        "Feel free to modify these or add more cells to help you test your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "HZZAkEJPJXqR"
      },
      "outputs": [],
      "source": [
        "# This will take a minute or so the first time you run it\n",
        "x_train, y_train, x_test, y_test, label_names, feature_names = load_digit_dataset()\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "UNda_lz4JXqR"
      },
      "source": [
        "We trained the autoencoder network on images with pixel values ranging from -1 to 1 rather than 0 to 255. So we'll provide two quick pre/post processing functions to make this quick adjustments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XzKiRyPzJXqR"
      },
      "outputs": [],
      "source": [
        "def preprocess(x):\n",
        "    # These scalar, element-wise operations are easy to write with NumPy\n",
        "\n",
        "    # Convert to 0 to 1\n",
        "    x = x/255\n",
        "\n",
        "    # Convert to -1 to 1\n",
        "    x = (x-0.5) * 2\n",
        "\n",
        "    return x\n",
        "\n",
        "def postprocess(x):\n",
        "    # These scalar, element-wise operations are easy to write with NumPy\n",
        "\n",
        "    # Convert to 0 to 1\n",
        "    x = (x+1) / 2\n",
        "\n",
        "    # Convert to 0 to 255\n",
        "    x = x * 255\n",
        "\n",
        "    x = x.astype(np.uint8)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "5g5XQkCgJXqR"
      },
      "outputs": [],
      "source": [
        "#@title Draw custom inputs { run: \"auto\"}\n",
        "z1 = 0 #@param {type:\"slider\", min:-30, max:30, step:0.5}\n",
        "z2 = 0 #@param {type:\"slider\", min:-30, max:30, step:0.5}\n",
        "\n",
        "z = np.array([z1, z2])\n",
        "\n",
        "x_prime = decode(z, params['W5'], params['b5'], params['W6'], params['b6'], params['W7'], params['b7'], params['W8'], params['b8'])\n",
        "\n",
        "x_prime = postprocess(x_prime)\n",
        "\n",
        "show_digit(x_prime)\n",
        "plt.figure()\n",
        "plt.plot(z[0], z[1], 'ro', markersize=12)\n",
        "plt.xlim(-30, 30)\n",
        "plt.ylim(-30, 30)\n",
        "# Show axes\n",
        "plt.axhline(0, color='lightgray')\n",
        "plt.axvline(0, color='lightgray')\n",
        "plt.xlabel(\"$z_1$\")\n",
        "plt.ylabel(\"$z_2$\")\n",
        "plt.title(\"Change values of z1 and z2 to create different output images!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8_qM7wGCJXqR"
      },
      "outputs": [],
      "source": [
        "# Let's see how well we can reconstruct the fifth image in the test input (index = 4)\n",
        "image_index = 4\n",
        "x = x_test[image_index]\n",
        "x = preprocess(x)\n",
        "\n",
        "z = encode(x, params['W1'], params['b1'], params['W2'], params['b2'], params['W3'], params['b3'], params['W4'], params['b4'])\n",
        "x_prime = decode(z, params['W5'], params['b5'], params['W6'], params['b6'], params['W7'], params['b7'], params['W8'], params['b8'])\n",
        "\n",
        "x_prime = postprocess(x_prime)\n",
        "\n",
        "show_digit(x_test[image_index])\n",
        "show_digit(x_prime)\n",
        "plt.figure()\n",
        "plt.plot(z[0], z[1], 'ro', markersize=12)\n",
        "plt.xlim(-30, 30)\n",
        "plt.ylim(-30, 30)\n",
        "# Show axes\n",
        "plt.axhline(0, color='lightgray')\n",
        "plt.axvline(0, color='lightgray')\n",
        "\n",
        "x_prime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "82f0t59EJXqR"
      },
      "outputs": [],
      "source": [
        "# Running on a range of test images\n",
        "for image_index in range(5):\n",
        "    x = x_test[image_index]\n",
        "    x = preprocess(x)\n",
        "\n",
        "    z = encode(x, params['W1'], params['b1'], params['W2'], params['b2'], params['W3'], params['b3'], params['W4'], params['b4'])\n",
        "    x_prime = decode(z, params['W5'], params['b5'], params['W6'], params['b6'], params['W7'], params['b7'], params['W8'], params['b8'])\n",
        "\n",
        "    x_prime = postprocess(x_prime)\n",
        "\n",
        "    show_digit(x_test[image_index])\n",
        "    show_digit(x_prime)\n",
        "    plt.figure()\n",
        "    plt.plot(z[0], z[1], 'ro', markersize=12)\n",
        "    plt.xlim(-30, 30)\n",
        "    plt.ylim(-30, 30)\n",
        "    # Show axes\n",
        "    plt.axhline(0, color='lightgray')\n",
        "    plt.axvline(0, color='lightgray')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "wrOTh9Z6JXqS"
      },
      "outputs": [],
      "source": [
        "# Test with really simple values to make sure the network functions are working\n",
        "\n",
        "x = np.zeros(784)\n",
        "\n",
        "z = encode(x, params['W1'], params['b1'], params['W2'], params['b2'], params['W3'], params['b3'], params['W4'], params['b4'])\n",
        "\n",
        "z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WqkhdOqjJXqS"
      },
      "outputs": [],
      "source": [
        "# Test with really simple values to make sure the network functions are working\n",
        "\n",
        "x = np.ones(784)\n",
        "\n",
        "z = encode(x, params['W1'], params['b1'], params['W2'], params['b2'], params['W3'], params['b3'], params['W4'], params['b4'])\n",
        "\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "PQnzqPzIJXqS"
      },
      "source": [
        "### Run the local autograder tests for this question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "8FjbjUsvJXqS"
      },
      "outputs": [],
      "source": [
        "grader.check(\"Q2c\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysKacjNcJXqS"
      },
      "source": [
        "### Links back to questions\n",
        "\n",
        "* [Q2a: Three neuron network](#q2a)\n",
        "* [Q2b: 28x28 image classification network](#q2b)\n",
        "* [Q2c: 28x28 image autoencoder network](#q2c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEeRGHZ3JXqS"
      },
      "source": [
        "## Submit your work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgteCbTLJXqS"
      },
      "source": [
        "### Submit your code to Gradescope\n",
        "\n",
        "Congratulations on finishing!!\n",
        "\n",
        "Save your notebook (or click File->Download->Download .ipynb) and then upload your `hw1.ipynb` file to Gradescope under assignment HW1 (programming).\n",
        "\n",
        "Not all of the tests are included in the local autograder. Some of the tests are \"hidden\" and only run in the server autograder on Gradescope.\n",
        "\n",
        "There is no limit on the number of submissions to Gradescope, so as you complete parts of the assignment it is a really good idea to save your notebook and upload it to Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXvggznoJXqT"
      },
      "source": [
        "### Check all of your work locally (but don't forget to submit to Gradescope)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}